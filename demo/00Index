The files

    npudens_serial.R
    npudens_npRmpi.R

demonstrate the difference between constructing serial versus parallel
MPI np programs via a simple density bandwidth selection
illustration. See also other similarly named files in this directory
for regression and conditional density examples, among others. 

Kindly study these files and the comments in each in order to extend
this approach to your problem.

Note - the output from the serial and parallel runs ought to be
_identical_ save for execution time. If they are not there is a
problem with the underlying code and I would ask you to kindly report
such things to me immediately along with the offending code.

*** Installation of the parallel MPI package `npRmpi'

Installation will depend on your hardware and software
configuration. If you are not familiar with parallel computing you
must seek local advice. 

That being said, if you have Open MPI and MPI2 properly installed on
your system, installation could be as simple as downloading the
tarball and, from a command shell, running

R CMD INSTALL npRmpi_xxx.tar.gz 

where xxx is the version number. 

For clusters you may additionally need to provide locations of
libraries (kindly see your local sysadmin as there are far too many
variations for me to assist). On a local Linux cluster I use the
following by way of illustration (we need to set MPI library paths and
MPI root directories):

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/sharcnet/openmpi/1.4.1/intel/lib
export MPI_ROOT=/opt/sharcnet/openmpi/1.4.1/intel 

R CMD INSTALL npRmpi_xxx.tar.gz

where again xxx is the version number. Please seek local help for
further assistance on installing and running parallel programs.

*** Serial (non-parallel) program batch execution:

To run the serial version (i.e. standard non-parallel version) install
the np program from CRAN and then, from a command shell, run

R CMD BATCH npudens_serial.R

*** Parallel MPI program batch execution:

To run the MPI version install the npRmpi program, copy the Rprofile
file in npRmpi/inst to the current directory and name it .Rprofile (or
copy it to your home directory and again name it .Rprofile) and then
on Open MPI systems run something like

mpirun -np 2 R CMD BATCH npudens_npRmpi.R

You can compare run times and any other differences by examining the
files npudens_serial.Rout and npudens_npRmpi.Rout. Clearly you could
do this with a subset of your data for large problems to judge the
extent to which the parallel code reduces run time. 

** Illustrative timed runs

These runs were performed using R 2.11 using Open MPI on a MacBook
running Snow Leopard 10.6.3 on a 2.4 GHz Intel Core 2 Duo. Code was
first run in serial mode using the np package then in parallel mode
with 2 processors using the npRmpi package version 0.30-8. Elapsed
time for the np functions is provided (seconds) as is the ratio of the
elapsed time for the parallel run to the serial run.

Note - many of these use smallish sample sizes hence the run time with
2 processors will not be 1/2 that with 1 processor due to
overhead. But for larger samples (i.e. the ones you need parallel
computing for, not these toy illustrations) you ought to see an
improvement that is linear in the number of processors.

npcdensls: np=1: 111.5, np=2: 125.0, ratio=0.89
npcdensml: np=1: 27.3, np=2: 48.8, ratio=0.56
npcmstest: np=1: 332.3, np=2: 592.4, ratio=0.56
npconmode: np=1: 38.2, np=2: 91.1, ratio=0.42
npindex: np=1: 18.6, np=2: 35.1, ratio=0.53
npreglc: np=1: 221.9, np=2: 346.2, ratio=0.64
npregll: np=1: 205.9, np=2: 441.4, ratio=0.47
npscoef: np=1: 31.6, np=2: 38.3, ratio=0.82
npsdeptest: np=1: 154.3, np=2: 254.5, ratio=0.61
npsigtest: np=1: 88.3, np=2: 156.2, ratio=0.56
npudens: np=1: 14.8, np=2: 25.3, ratio=0.59
